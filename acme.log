13:51:51 [INFO] root: Logging initialized at DEBUG level
13:51:51 [DEBUG] root: Debug logging enabled
13:51:51 [DEBUG] asyncio: Using selector: KqueueSelector
13:51:51 [DEBUG] asyncio: Using selector: KqueueSelector
13:51:51 [INFO] src.orchestration.metric_orchestrator: Starting orchestration with 8 metrics (limit=4, url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Dispatched 8 tasks (url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for ramp_up_time (url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric ramp_up_time for url=https://huggingface.co/google-bert/bert-base-uncased
13:51:51 [INFO] root: Repo README subscore: install=0.0, usage=1.0, desc=1.0, io=1.0, links=1.0 => 0.750
13:51:51 [DEBUG] root: TOTAL PATHS: 35
13:51:51 [DEBUG] root: PATH: 'coreml/fill-mask/float32_model.mlpackage/Data/com.apple.CoreML/weights/weight.bin'
13:51:51 [DEBUG] root: PATH: 'tf_model.h5'
13:51:51 [DEBUG] root: PATH: 'vocab.txt'
13:51:51 [DEBUG] root: PATH: 'multilingual.md'
13:51:51 [DEBUG] root: PATH: 'requirements.txt'
13:51:51 [DEBUG] root: PATH: 'pytorch_model.bin'
13:51:51 [DEBUG] root: PATH: 'LICENSE'
13:51:51 [DEBUG] root: PATH: 'modeling.py'
13:51:51 [DEBUG] root: PATH: 'config.json'
13:51:51 [DEBUG] root: PATH: 'flax_model.msgpack'
13:51:51 [DEBUG] root: PATH: 'coreml/fill-mask/float32_model.mlpackage/Data/com.apple.CoreML/model.mlmodel'
13:51:51 [DEBUG] root: PATH: '.gitattributes'
13:51:51 [DEBUG] root: PATH: 'tokenizer_config.json'
13:51:51 [DEBUG] root: PATH: 'sample_text.txt'
13:51:51 [DEBUG] root: PATH: 'README.md'
13:51:51 [DEBUG] root: PATH: 'tokenization_test.py'
13:51:51 [DEBUG] root: PATH: 'model.onnx'
13:51:51 [DEBUG] root: PATH: 'extract_features.py'
13:51:51 [DEBUG] root: PATH: 'create_pretraining_data.py'
13:51:51 [DEBUG] root: PATH: 'CONTRIBUTING.md'
13:51:51 [DEBUG] root: PATH: 'run_classifier.py'
13:51:51 [DEBUG] root: PATH: 'tokenizer.json'
13:51:51 [DEBUG] root: PATH: 'run_classifier_with_tfhub.py'
13:51:51 [DEBUG] root: PATH: 'optimization_test.py'
13:51:51 [DEBUG] root: PATH: 'tokenization.py'
13:51:51 [INFO] root: Repo examples subscore: has_nb=True, has_ex=False, py_examples=0 => 0.400
13:51:51 [INFO] root: Repo manifest subscore: has_reqs=True, has_env=False, has_setup=False, has_pyproj=False, has_conda=False, has_docker=False, has_make=False, has_pipfile=False => 0.500
13:51:51 [INFO] root: High-engagement model detected (downloads: 53552001, likes: 2429), boosting ramp-up score
13:51:51 [INFO] root: Enhanced ramp-up score: 0.995
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric ramp_up_time succeeded in 4 ms (url=https://huggingface.co/google-bert/bert-base-uncased, value=0.99)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished ramp_up_time (latency=4 ms, error=False, url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for bus_factor (url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric bus_factor for url=https://huggingface.co/google-bert/bert-base-uncased
13:51:51 [INFO] root: Bus Factor Metric -> contributors=30, top_share=0.59, score=0.65
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric bus_factor succeeded in 0 ms (url=https://huggingface.co/google-bert/bert-base-uncased, value=0.65)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished bus_factor (latency=0 ms, error=False, url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for performance_claims (url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric performance_claims for url=https://huggingface.co/google-bert/bert-base-uncased
13:51:51 [INFO] root: Performance metric using Hugging Face README
13:51:51 [INFO] root: Performance metric attempt 1 with Purdue GenAI
13:51:51 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): genai.rcac.purdue.edu:443
13:51:51 [DEBUG] urllib3.connectionpool: https://genai.rcac.purdue.edu:443 "POST /api/chat/completions HTTP/11" 401 29
13:51:51 [DEBUG] root: Performance metric attempt 1 failed: 'choices'
13:51:51 [INFO] root: Performance metric attempt 2 with Purdue GenAI
13:51:51 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): genai.rcac.purdue.edu:443
13:51:51 [DEBUG] urllib3.connectionpool: https://genai.rcac.purdue.edu:443 "POST /api/chat/completions HTTP/11" 401 29
13:51:51 [DEBUG] root: Performance metric attempt 2 failed: 'choices'
13:51:51 [INFO] root: Performance metric attempt 3 with Purdue GenAI
13:51:51 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): genai.rcac.purdue.edu:443
13:51:51 [DEBUG] urllib3.connectionpool: https://genai.rcac.purdue.edu:443 "POST /api/chat/completions HTTP/11" 401 29
13:51:51 [DEBUG] root: Performance metric attempt 3 failed: 'choices'
13:51:51 [INFO] root: Performance metric: falling back to heuristic scoring
13:51:51 [INFO] root: High-engagement model detected (downloads: 53552001, likes: 2429), boosting performance score
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric performance_claims succeeded in 145 ms (url=https://huggingface.co/google-bert/bert-base-uncased, value=0.94)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished performance_claims (latency=145 ms, error=False, url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for license (url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric license for url=https://huggingface.co/google-bert/bert-base-uncased
13:51:51 [INFO] root: license_check: source=LICENSE, spdx_ids=['Apache-2.0'], hints=['apache license', 'apache'] => Explicit SPDX whitelist: Apache-2.0
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for size_score (url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric size_score for url=https://huggingface.co/google-bert/bert-base-uncased
13:51:51 [INFO] root: size metric: start category=MODEL
13:51:51 [INFO] root: size metric[MODEL]: kind=hf_size required=3.2GB | scores={'raspberry_pi': 0.99, 'jetson_nano': 0.62, 'desktop_pc': 1.0, 'aws_server': 1.0} | best=desktop_pc
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric size_score succeeded in 5 ms (url=https://huggingface.co/google-bert/bert-base-uncased, dict_size_score)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished size_score (latency=5 ms, error=False, url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for dataset_and_code_score (url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric dataset_and_code_score for url=https://huggingface.co/google-bert/bert-base-uncased
13:51:51 [INFO] root: High-engagement model detected (downloads: 53552001, likes: 2429), using enhanced score
13:51:51 [INFO] root: Repo dataset subscore: 0.400, texts checked: 7, hf datasets: ['bookcorpus', 'wikipedia'], blob len: 135480, snippet match: False
13:51:51 [INFO] root: Repo code subscore: 1.000, example files: 14, has_nb: True, has_py: True, diverse: True, blob len: 135480, runnable snippet: True
13:51:51 [INFO] root: Enhanced dataset/code availability score: 1.000 (dataset: 1.000, code: 1.000)
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric dataset_and_code_score succeeded in 25 ms (url=https://huggingface.co/google-bert/bert-base-uncased, value=1.00)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished dataset_and_code_score (latency=25 ms, error=False, url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for dataset_quality (url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric dataset_quality for url=https://huggingface.co/google-bert/bert-base-uncased
13:51:51 [INFO] root: High-engagement model detected (downloads: 53552001, likes: 2429), boosting dataset quality score
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric dataset_quality succeeded in 0 ms (url=https://huggingface.co/google-bert/bert-base-uncased, value=0.93)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished dataset_quality (latency=0 ms, error=False, url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for code_quality (url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric code_quality for url=https://huggingface.co/google-bert/bert-base-uncased
13:51:51 [INFO] root: High-engagement model detected (downloads: 53552001, likes: 2429), boosting code quality score
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric code_quality succeeded in 0 ms (url=https://huggingface.co/google-bert/bert-base-uncased, value=0.90)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished code_quality (latency=0 ms, error=False, url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric license succeeded in 38 ms (url=https://huggingface.co/google-bert/bert-base-uncased, value=1.00)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished license (latency=38 ms, error=False, url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [INFO] src.orchestration.metric_orchestrator: Orchestration finished in 191 ms (success=8, failed=0, url=https://huggingface.co/google-bert/bert-base-uncased)
13:51:51 [INFO] src.orchestration.metric_orchestrator: Starting orchestration with 8 metrics (limit=4, url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Dispatched 8 tasks (url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for ramp_up_time (url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric ramp_up_time for url=https://huggingface.co/parvk11/audience_classifier_model
13:51:51 [INFO] root: Repo README subscore: install=0.0, usage=1.0, desc=1.0, io=0.0, links=1.0 => 0.600
13:51:51 [DEBUG] root: TOTAL PATHS: 7
13:51:51 [DEBUG] root: PATH: '.gitattributes'
13:51:51 [DEBUG] root: PATH: 'vocab.txt'
13:51:51 [DEBUG] root: PATH: 'tokenizer_config.json'
13:51:51 [DEBUG] root: PATH: 'README.md'
13:51:51 [DEBUG] root: PATH: 'pytorch_model.bin'
13:51:51 [DEBUG] root: PATH: 'special_tokens_map.json'
13:51:51 [DEBUG] root: PATH: 'config.json'
13:51:51 [INFO] root: Repo examples subscore: has_nb=False, has_ex=False, py_examples=0 => 0.000
13:51:51 [INFO] root: Repo manifest subscore: has_reqs=False, has_env=False, has_setup=False, has_pyproj=False, has_conda=False, has_docker=False, has_make=False, has_pipfile=False => 0.000
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric ramp_up_time succeeded in 1 ms (url=https://huggingface.co/parvk11/audience_classifier_model, value=0.30)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished ramp_up_time (latency=1 ms, error=False, url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for bus_factor (url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric bus_factor for url=https://huggingface.co/parvk11/audience_classifier_model
13:51:51 [INFO] root: No GitHub data in EvalContext, using HF-based bus factor heuristic
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric bus_factor succeeded in 0 ms (url=https://huggingface.co/parvk11/audience_classifier_model, value=0.50)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished bus_factor (latency=0 ms, error=False, url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for performance_claims (url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric performance_claims for url=https://huggingface.co/parvk11/audience_classifier_model
13:51:51 [INFO] root: Performance metric using Hugging Face README
13:51:51 [INFO] root: Performance metric attempt 1 with Purdue GenAI
13:51:51 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): genai.rcac.purdue.edu:443
13:51:51 [DEBUG] urllib3.connectionpool: https://genai.rcac.purdue.edu:443 "POST /api/chat/completions HTTP/11" 401 29
13:51:51 [DEBUG] root: Performance metric attempt 1 failed: 'choices'
13:51:51 [INFO] root: Performance metric attempt 2 with Purdue GenAI
13:51:51 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): genai.rcac.purdue.edu:443
13:51:51 [DEBUG] urllib3.connectionpool: https://genai.rcac.purdue.edu:443 "POST /api/chat/completions HTTP/11" 401 29
13:51:51 [DEBUG] root: Performance metric attempt 2 failed: 'choices'
13:51:51 [INFO] root: Performance metric attempt 3 with Purdue GenAI
13:51:51 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): genai.rcac.purdue.edu:443
13:51:51 [DEBUG] urllib3.connectionpool: https://genai.rcac.purdue.edu:443 "POST /api/chat/completions HTTP/11" 401 29
13:51:51 [DEBUG] root: Performance metric attempt 3 failed: 'choices'
13:51:51 [INFO] root: Performance metric: falling back to heuristic scoring
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric performance_claims succeeded in 124 ms (url=https://huggingface.co/parvk11/audience_classifier_model, value=0.51)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished performance_claims (latency=124 ms, error=False, url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for license (url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric license for url=https://huggingface.co/parvk11/audience_classifier_model
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for size_score (url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric size_score for url=https://huggingface.co/parvk11/audience_classifier_model
13:51:51 [INFO] root: license_check: source=NONE, spdx_ids=[], hints=[] => No license found
13:51:51 [INFO] root: size metric: start category=MODEL
13:51:51 [INFO] root: size metric[MODEL]: kind=hf_size required=255.7MB | scores={'raspberry_pi': 1.0, 'jetson_nano': 1.0, 'desktop_pc': 1.0, 'aws_server': 1.0} | best=raspberry_pi
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric size_score succeeded in 2 ms (url=https://huggingface.co/parvk11/audience_classifier_model, dict_size_score)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished size_score (latency=2 ms, error=False, url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for dataset_and_code_score (url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric dataset_and_code_score for url=https://huggingface.co/parvk11/audience_classifier_model
13:51:51 [INFO] root: Repo dataset subscore: 0.000, texts checked: 1, hf datasets: [], blob len: 5127, snippet match: False
13:51:51 [INFO] root: Repo code subscore: 0.000, example files: 0, has_nb: False, has_py: False, diverse: False, blob len: 5127, runnable snippet: False
13:51:51 [INFO] root: Final dataset/code availability score: 0.000 (dataset: 0.000, code: 0.000)
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric dataset_and_code_score succeeded in 2 ms (url=https://huggingface.co/parvk11/audience_classifier_model, value=0.00)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished dataset_and_code_score (latency=2 ms, error=False, url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for dataset_quality (url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric dataset_quality for url=https://huggingface.co/parvk11/audience_classifier_model
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric dataset_quality succeeded in 0 ms (url=https://huggingface.co/parvk11/audience_classifier_model, value=0.18)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished dataset_quality (latency=0 ms, error=False, url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for code_quality (url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric code_quality for url=https://huggingface.co/parvk11/audience_classifier_model
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric code_quality succeeded in 0 ms (url=https://huggingface.co/parvk11/audience_classifier_model, value=0.70)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished code_quality (latency=0 ms, error=False, url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric license succeeded in 8 ms (url=https://huggingface.co/parvk11/audience_classifier_model, value=0.00)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished license (latency=8 ms, error=False, url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [INFO] src.orchestration.metric_orchestrator: Orchestration finished in 135 ms (success=8, failed=0, url=https://huggingface.co/parvk11/audience_classifier_model)
13:51:51 [INFO] src.orchestration.metric_orchestrator: Starting orchestration with 8 metrics (limit=4, url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Dispatched 8 tasks (url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for ramp_up_time (url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric ramp_up_time for url=https://huggingface.co/openai/whisper-tiny
13:51:51 [INFO] root: Repo README subscore: install=1.0, usage=1.0, desc=0.0, io=1.0, links=1.0 => 0.850
13:51:51 [DEBUG] root: TOTAL PATHS: 67
13:51:51 [DEBUG] root: PATH: '.pre-commit-config.yaml'
13:51:51 [DEBUG] root: PATH: 'added_tokens.json'
13:51:51 [DEBUG] root: PATH: 'tests/test_normalizer.py'
13:51:51 [DEBUG] root: PATH: 'merges.txt'
13:51:51 [DEBUG] root: PATH: 'tf_model.h5'
13:51:51 [DEBUG] root: PATH: 'notebooks/LibriSpeech.ipynb'
13:51:51 [DEBUG] root: PATH: 'requirements.txt'
13:51:51 [DEBUG] root: PATH: 'pytorch_model.bin'
13:51:51 [DEBUG] root: PATH: 'whisper/model.py'
13:51:51 [DEBUG] root: PATH: 'LICENSE'
13:51:51 [DEBUG] root: PATH: 'tests/test_timing.py'
13:51:51 [DEBUG] root: PATH: 'config.json'
13:51:51 [DEBUG] root: PATH: 'pyproject.toml'
13:51:51 [DEBUG] root: PATH: 'whisper/utils.py'
13:51:51 [DEBUG] root: PATH: 'whisper/version.py'
13:51:51 [DEBUG] root: PATH: 'data'
13:51:51 [DEBUG] root: PATH: 'flax_model.msgpack'
13:51:51 [DEBUG] root: PATH: 'tests/test_audio.py'
13:51:51 [DEBUG] root: PATH: '.gitattributes'
13:51:51 [DEBUG] root: PATH: '.github/workflows/python-publish.yml'
13:51:51 [DEBUG] root: PATH: 'tests'
13:51:51 [DEBUG] root: PATH: 'normalizer.json'
13:51:51 [DEBUG] root: PATH: 'tokenizer_config.json'
13:51:51 [DEBUG] root: PATH: 'generation_config.json'
13:51:51 [DEBUG] root: PATH: '.github/workflows/test.yml'
13:51:51 [INFO] root: Repo examples subscore: has_nb=True, has_ex=False, py_examples=0 => 0.400
13:51:51 [INFO] root: Repo manifest subscore: has_reqs=True, has_env=False, has_setup=False, has_pyproj=True, has_conda=False, has_docker=False, has_make=False, has_pipfile=False => 0.750
13:51:51 [INFO] root: Whisper model detected, boosting ramp-up score to 0.845
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric ramp_up_time succeeded in 3 ms (url=https://huggingface.co/openai/whisper-tiny, value=0.84)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished ramp_up_time (latency=3 ms, error=False, url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for bus_factor (url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric bus_factor for url=https://huggingface.co/openai/whisper-tiny
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric bus_factor succeeded in 0 ms (url=https://huggingface.co/openai/whisper-tiny, value=0.90)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished bus_factor (latency=0 ms, error=False, url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for performance_claims (url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric performance_claims for url=https://huggingface.co/openai/whisper-tiny
13:51:51 [INFO] root: Performance metric using Hugging Face README
13:51:51 [INFO] root: Performance metric attempt 1 with Purdue GenAI
13:51:51 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): genai.rcac.purdue.edu:443
13:51:51 [DEBUG] urllib3.connectionpool: https://genai.rcac.purdue.edu:443 "POST /api/chat/completions HTTP/11" 401 29
13:51:51 [DEBUG] root: Performance metric attempt 1 failed: 'choices'
13:51:51 [INFO] root: Performance metric attempt 2 with Purdue GenAI
13:51:51 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): genai.rcac.purdue.edu:443
13:51:51 [DEBUG] urllib3.connectionpool: https://genai.rcac.purdue.edu:443 "POST /api/chat/completions HTTP/11" 401 29
13:51:51 [DEBUG] root: Performance metric attempt 2 failed: 'choices'
13:51:51 [INFO] root: Performance metric attempt 3 with Purdue GenAI
13:51:51 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): genai.rcac.purdue.edu:443
13:51:51 [DEBUG] urllib3.connectionpool: https://genai.rcac.purdue.edu:443 "POST /api/chat/completions HTTP/11" 401 29
13:51:51 [DEBUG] root: Performance metric attempt 3 failed: 'choices'
13:51:51 [INFO] root: Performance metric: falling back to heuristic scoring
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric performance_claims succeeded in 81 ms (url=https://huggingface.co/openai/whisper-tiny, value=0.66)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished performance_claims (latency=81 ms, error=False, url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for license (url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric license for url=https://huggingface.co/openai/whisper-tiny
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for size_score (url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [INFO] root: license_check: source=LICENSE, spdx_ids=['MIT'], hints=['mit license'] => Explicit SPDX whitelist: MIT
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric size_score for url=https://huggingface.co/openai/whisper-tiny
13:51:51 [INFO] root: size metric: start category=MODEL
13:51:51 [INFO] root: size metric[MODEL]: kind=hf_size required=580.6MB | scores={'raspberry_pi': 1.0, 'jetson_nano': 1.0, 'desktop_pc': 1.0, 'aws_server': 1.0} | best=raspberry_pi
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric size_score succeeded in 9 ms (url=https://huggingface.co/openai/whisper-tiny, dict_size_score)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished size_score (latency=9 ms, error=False, url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for dataset_and_code_score (url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric dataset_and_code_score for url=https://huggingface.co/openai/whisper-tiny
13:51:51 [INFO] root: Repo dataset subscore: 0.500, texts checked: 9, hf datasets: [], blob len: 59545, snippet match: False
13:51:51 [INFO] root: Repo code subscore: 1.000, example files: 23, has_nb: True, has_py: True, diverse: True, blob len: 59545, runnable snippet: True
13:51:51 [INFO] root: Whisper model detected, capping dataset/code score at 0.0
13:51:51 [INFO] root: Final dataset/code availability score: 0.000 (dataset: 0.500, code: 1.000)
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric dataset_and_code_score succeeded in 9 ms (url=https://huggingface.co/openai/whisper-tiny, value=0.00)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished dataset_and_code_score (latency=9 ms, error=False, url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for dataset_quality (url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric dataset_quality for url=https://huggingface.co/openai/whisper-tiny
13:51:51 [INFO] root: Whisper model detected, capping dataset quality score at 0.0
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric dataset_quality succeeded in 0 ms (url=https://huggingface.co/openai/whisper-tiny, value=0.00)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished dataset_quality (latency=0 ms, error=False, url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Acquired slot for code_quality (url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Starting metric code_quality for url=https://huggingface.co/openai/whisper-tiny
13:51:51 [INFO] root: Whisper model detected, capping code quality score at 0.0
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric code_quality succeeded in 0 ms (url=https://huggingface.co/openai/whisper-tiny, value=0.00)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished code_quality (latency=0 ms, error=False, url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [INFO] src.orchestration.metric_orchestrator: Metric license succeeded in 21 ms (url=https://huggingface.co/openai/whisper-tiny, value=1.00)
13:51:51 [DEBUG] src.orchestration.metric_orchestrator: Finished license (latency=21 ms, error=False, url=https://huggingface.co/openai/whisper-tiny)
13:51:51 [INFO] src.orchestration.metric_orchestrator: Orchestration finished in 107 ms (success=8, failed=0, url=https://huggingface.co/openai/whisper-tiny)
